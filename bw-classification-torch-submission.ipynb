{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":40398,"sourceType":"modelInstanceVersion","modelInstanceId":34018}],"dockerImageVersionId":30699,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-27T10:18:55.113184Z","iopub.execute_input":"2024-04-27T10:18:55.113560Z","iopub.status.idle":"2024-04-27T10:18:55.118876Z","shell.execute_reply.started":"2024-04-27T10:18:55.113529Z","shell.execute_reply":"2024-04-27T10:18:55.117721Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nimport timm\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:19:38.048126Z","iopub.execute_input":"2024-04-27T10:19:38.049112Z","iopub.status.idle":"2024-04-27T10:19:38.053410Z","shell.execute_reply.started":"2024-04-27T10:19:38.049075Z","shell.execute_reply":"2024-04-27T10:19:38.052463Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model_path = \"/kaggle/input/resnet34d_hmsbrain_5e_512i/pytorch/1/1/resnet34d_5E_512.pth\"\nmodel = timm.create_model('resnet34d', pretrained=False, num_classes=6, in_chans=3)\nmodel.load_state_dict(torch.load(model_path))\nmodel.to(device)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:19:43.138705Z","iopub.execute_input":"2024-04-27T10:19:43.139073Z","iopub.status.idle":"2024-04-27T10:19:43.715805Z","shell.execute_reply.started":"2024-04-27T10:19:43.139044Z","shell.execute_reply":"2024-04-27T10:19:43.714744Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  )\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n    (4): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n    (5): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n  )\n  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n  (fc): Linear(in_features=512, out_features=6, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def get_data(paths):\n    \"\"\"\n    given a list of paths [0-10], the function will collect parquet file for each path/parquet file\n    do data preporcessing - na value, clip, log, normalization, resize to meet model input\n    convert to tensors\n    \n    return stacked tensor of all the parquet files passed\n    \"\"\"\n    eps = 1e-6 # incase data_std returns 0\n    batch_data = []\n    for path in paths:\n        data = pd.read_parquet(path)\n        data = data.fillna(-1).values[:, 1:].T\n        data = np.clip(data, np.exp(-6), np.exp(10)) # avioid log(0)\n        data = np.log(data)\n        \n        data_mean = data.mean(axis=(0, 1))\n        data_std = data.std(axis=(0, 1))\n        data = (data - data_mean) / (data_std + eps)\n        \n        data_tensor = torch.unsqueeze(torch.Tensor(data), dim=0)\n        data = Config.image_transform(data_tensor)\n        \n        batch_data.append(data)\n        \n    return torch.stack(batch_data)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:29:54.839764Z","iopub.execute_input":"2024-04-27T10:29:54.840159Z","iopub.status.idle":"2024-04-27T10:29:54.848042Z","shell.execute_reply.started":"2024-04-27T10:29:54.840127Z","shell.execute_reply":"2024-04-27T10:29:54.847057Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def submission_ready(single_path):\n    data = get_data([single_path])\n    data = torch.cat([data, data, data], dim = 1)\n    pred = model(data.to(device))\n    return pred","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:41:43.328492Z","iopub.execute_input":"2024-04-27T10:41:43.328837Z","iopub.status.idle":"2024-04-27T10:41:43.334084Z","shell.execute_reply.started":"2024-04-27T10:41:43.328812Z","shell.execute_reply":"2024-04-27T10:41:43.333059Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:42:35.773382Z","iopub.execute_input":"2024-04-27T10:42:35.774209Z","iopub.status.idle":"2024-04-27T10:42:35.778697Z","shell.execute_reply.started":"2024-04-27T10:42:35.774174Z","shell.execute_reply":"2024-04-27T10:42:35.777690Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class Config:\n    seed = 42\n    image_transform = transforms.Resize((512, 512))\n    batch_size = 16\n    num_epochs = 5","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:39:58.147573Z","iopub.execute_input":"2024-04-27T10:39:58.148188Z","iopub.status.idle":"2024-04-27T10:39:58.152892Z","shell.execute_reply.started":"2024-04-27T10:39:58.148155Z","shell.execute_reply":"2024-04-27T10:39:58.151950Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\")\ntest_df","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:23:14.193522Z","iopub.execute_input":"2024-04-27T10:23:14.193892Z","iopub.status.idle":"2024-04-27T10:23:14.223216Z","shell.execute_reply.started":"2024-04-27T10:23:14.193864Z","shell.execute_reply":"2024-04-27T10:23:14.222166Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   spectrogram_id      eeg_id  patient_id\n0          853520  3911565283        6885","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spectrogram_id</th>\n      <th>eeg_id</th>\n      <th>patient_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>853520</td>\n      <td>3911565283</td>\n      <td>6885</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = test_df[[\"spectrogram_id\"]].copy()\ndf[\"path\"] = df[\"spectrogram_id\"].apply(lambda x: \"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/\" + str(x) + \".parquet\")\ndf","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:27:23.647893Z","iopub.execute_input":"2024-04-27T10:27:23.648757Z","iopub.status.idle":"2024-04-27T10:27:23.659433Z","shell.execute_reply.started":"2024-04-27T10:27:23.648724Z","shell.execute_reply":"2024-04-27T10:27:23.658366Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   spectrogram_id                                               path\n0          853520  /kaggle/input/hms-harmful-brain-activity-class...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spectrogram_id</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>853520</td>\n      <td>/kaggle/input/hms-harmful-brain-activity-class...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y_features = [\"seizure_vote_sum\", \n              \"lpd_vote_sum\", \n              \"gpd_vote_sum\", \n              \"lrda_vote_sum\", \n              \"grda_vote_sum\", \n              \"other_vote_sum\"]","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:24:52.809040Z","iopub.execute_input":"2024-04-27T10:24:52.809739Z","iopub.status.idle":"2024-04-27T10:24:52.814143Z","shell.execute_reply.started":"2024-04-27T10:24:52.809704Z","shell.execute_reply":"2024-04-27T10:24:52.813119Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\neeg = []\nseizure_vote_sum = []\nlpd_vote_sum = []\ngpd_vote_sum = []\nlrda_vote_sum = []\ngrda_vote_sum = []\nother_vote_sum = []\n\nfor index, path in enumerate(df[\"path\"]):\n    pred_list = submission_ready(path)\n    pred_list = F.softmax(pred_list, dim = 1)\n    pred_list = pred_list.tolist()[0]\n    eeg_id = test_df.iloc[index][\"eeg_id\"]\n    eeg.append(eeg_id)\n    seizure_vote_sum.append(pred_list[0])\n    lpd_vote_sum.append(pred_list[1])\n    gpd_vote_sum.append(pred_list[2])\n    lrda_vote_sum.append(pred_list[3])\n    grda_vote_sum.append(pred_list[4])\n    other_vote_sum.append(pred_list[5])","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:53:08.968469Z","iopub.execute_input":"2024-04-27T10:53:08.969150Z","iopub.status.idle":"2024-04-27T10:53:09.020758Z","shell.execute_reply.started":"2024-04-27T10:53:08.969120Z","shell.execute_reply":"2024-04-27T10:53:09.019775Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"data = {\n    'eeg_id': eeg,\n    'seizure_vote': seizure_vote_sum,\n    'lpd_vote': lpd_vote_sum,\n    'gpd_vote': gpd_vote_sum,\n    'lrda_vote': lrda_vote_sum,\n    'grda_vote': grda_vote_sum,\n    'other_vote': other_vote_sum\n}\nsub_df = pd.DataFrame(data)\nsub_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T11:08:04.298916Z","iopub.execute_input":"2024-04-27T11:08:04.299302Z","iopub.status.idle":"2024-04-27T11:08:04.307595Z","shell.execute_reply.started":"2024-04-27T11:08:04.299273Z","shell.execute_reply":"2024-04-27T11:08:04.306635Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"sub_df","metadata":{"execution":{"iopub.status.busy":"2024-04-27T11:08:04.558378Z","iopub.execute_input":"2024-04-27T11:08:04.558741Z","iopub.status.idle":"2024-04-27T11:08:04.572425Z","shell.execute_reply.started":"2024-04-27T11:08:04.558713Z","shell.execute_reply":"2024-04-27T11:08:04.571361Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n0  3911565283      0.143057  0.151177   0.13985   0.260793   0.126878   \n\n   other_vote  \n0    0.178246  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eeg_id</th>\n      <th>seizure_vote</th>\n      <th>lpd_vote</th>\n      <th>gpd_vote</th>\n      <th>lrda_vote</th>\n      <th>grda_vote</th>\n      <th>other_vote</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3911565283</td>\n      <td>0.143057</td>\n      <td>0.151177</td>\n      <td>0.13985</td>\n      <td>0.260793</td>\n      <td>0.126878</td>\n      <td>0.178246</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}